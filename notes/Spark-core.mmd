Mind Map generated by NB MindMap plugin   
> __version__=`1.1`,showJumps=`true`
---

# spark\-core

## 术语

## 架构

## 应用

### 编程模型

#### RDD

##### A Resilient Distributed Dataset

###### HadoopRDD

####### 文件数据输入

###### MapPartitionsRDD

##### A list of partitions  SPLITS

##### A function for computing each split e\.g\. flatMmap作用在每个分区的每一条记录上

##### A list of dependencies on other RDDs

##### a Partitioner for key\-value RDDs

##### a list of preferred locations to compute each split

#### 算子

##### create

###### sc\.textfile

##### transform

###### map、flatMap、filter

###### reduceByKey/combineByKey、sortbykey

##### control

###### cache、persist、checkpoint

###### repartition、colase

##### action

###### foreach、collect、take、count

#### dependencies

##### narrow

##### shuffle

###### handle

####### SortShuffleManager

######## writer

######## reader

###### mapSiteCombine

###### aggrator

###### seri\.\.\.

###### keyOrder

###### rdd

#### 面向RDD

##### iterator是模板方法

###### persist中去查找有没有存过数据

####### blockmanager中取数据

###### checkpoint

####### 从hdfs中取数据

###### comput

####### hadoopRDD

######## 对文件包装成iter

####### ShuffledRDD

######## 调用了shuffle\-reader

##### 是一个单向链表

###### lineage

####### 血统

###### pipeline

####### iterator的嵌套迭代引用

####### 在一个task中

## 源码

### 基于standalone

#### 资源层

##### 角色

###### master

####### 接受worker的注册、资源的整理

####### 接受计算层的资源申请

######## Driver

######## Executor

######### registerApplication

###### workers

####### 启动计算层角色

####### 向master汇报资源使用

##### RPC

###### Endpoint

####### ref

####### send、ask

####### receive、receiveAndReplay

###### Dispatcher

####### receivers队列

###### Netty

#### 计算层

##### client、cluster

###### driver在哪里

####### 什么是driver

######## SparkContext

######## SparkContext就是我们自己的逻辑实现

##### cluster

###### 1，client

####### 通过资源层申请Driver

###### 2，Driver

####### sparkcontext

######## backend

######### driverEndpoint

######### appClient

########## 去资源层的master注册

########### 在master中触发资源调度

############ 产生executor

###### 3，ExecutorBackEnd

####### 向Driver反向注册

####### Executor

######## threadPool

######### task

##### 任务调度和执行

###### 1，rdd的action算子

####### sc\.runJob

###### 2，DAGScheduler

####### 是把job的最后一个rdd作为参数 \(先说出这句话\)

####### stage

######## 最后一个rdd代表最后一个stage

######### stage中只有一个rdd对象的参数引用

####### 递归\+循环

######## 递归

######### 以stage换言之以shuffleDep为边界

######## 循环

######### 寻找shuffleDep的过程是触发的循环遍历，避免了栈溢出

####### 回归过程中触发task调度提交

####### stage

######## task的数量是最后一个RDD的分区的数量决定的

######## 最佳计算位置

######## stage会产生一个taskbinary，并广播出去

######## 一个stage根据分区数，产生对应的task

######## 最终将tasks填充到taskset

######### 触发TaskScheduler

###### 3，TaskScheduler

####### scheduleMode

######## FIFO

######## Pair

####### TaskSetManager

###### 4，Executor

####### runtask

######## SparkEnv

######### memoryManager

########## executionMemory

########## memoryStore

######### blockManager

########## mem

########## disk

######### mapoutputracker

######### nettytransformserver

########## 拉取数据

######### sortShuffleManager

######## task

######### 1，输入

########## hadooprdd

########## persist

########### mem

########### Disk

########## checkpoint

########### HDFS

########## shuffle\-reader

######### 2，计算

########## pipeline：iter

######### 3，输出

########## shuffle\-writer

########### 存储到磁盘

########## result

########### 回收到客户端或者Driver

######## sortShuffleManager

######### registerHandle

######### getWriter

########## bypass

########### 无缓冲区，直接写出去了

########## base

########### map

########### buffer

########## unsafe

######### getReader

########## dep

########### iter

######## BlockManager

######### shuffle\-writer

########## 结果写到磁盘

########### disk

######### persist

########## StroageLevel

########### MemoryOnly

########### MemoryAndDisk

########### ser

############ 序列化

######### broadcast

######## taskMemoryManager

######### 每task一个

######### 计算过程中

########## shuffle\-writer

########### unsafe

########### base

########### 计算过程中向MemoryManager申请缓冲区：ExecutionMemory
