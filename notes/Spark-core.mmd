Mind Map generated by NB MindMap plugin   
> __version__=`1.1`,showJumps=`true`
---

# spark\-core

## 术语

## 架构

## 应用

### 编程模型

#### RDD

##### A Resilient Distributed Dataset

###### HadoopRDD

####### 文件数据输入

###### MapPartitionsRDD

##### A list of partitions  SPLITS

##### A function for computing each split

##### A list of dependencies on other RDDs

##### a Partitioner for key\-value RDDs

##### a list of preferred locations to compute each split

#### 算子

##### create

###### sc\.textfile

##### transform

###### map、flatMap、filter

###### reduceByKey/combineByKey、sortbykey

##### control

###### cache、persist、checkpoint

###### repartition、colase

##### action

###### foreach、collect、take、count

#### dependencie

##### narrow

##### shuffle

###### handle

####### SortShuffleManager

######## writer

######## reader

###### mapSiteCombine

###### aggrator

###### seri\.\.\.

###### keyOrder

###### rdd

#### 面向RDD

##### iterator是模板方法

###### persist中去查找有没有存过数据

####### blockmanager中取数据

###### checkpoint

####### 从hdfs中取数据

###### comput

####### hadoopRDD

######## 对文件包装成iter

####### ShuffledRDD

######## 调用了shuffle\-reader

##### 是一个单向链表

###### lineage

####### 血统

###### pipeline

####### iterator的嵌套迭代引用

####### 在一个task中

## 源码

### 基于standalone

#### 资源层

##### 角色

###### master

####### 接受worker的注册、资源的整理

####### 接受计算层的资源申请

######## Driver

######## Executor

######### registerApplication

###### workers

####### 是启动计算层角色

####### 向master汇报资源使用

##### RPC

###### Endpoint

####### ref

####### send、ask

####### recvie、reciveAndReplay

###### Dispatcher

###### Netty

#### 计算层

##### client、cluster

###### driver在哪里

####### 什么是driver

######## sparkcontext

######## 就是我们自己的逻辑实现

##### cluster

###### 1，client

####### 通过资源层申请Driver

###### 2，Driver

####### sparkcontext

######## backend

######### driverEndpoint

######### appClient

########## 去资源层的master注册

########### 在master中触发资源调度

############ 产生executor

###### 3，ExecutorBackEnd

####### 向Driver反向注册

####### Executor

######## threadPool

######### task

##### 任务调度和执行

###### 1，rdd的action算子

####### sc\.runJob

###### 2，DAGScheduler

####### 是把job的最后一个rdd作为参数

####### stage

######## 最后一个rdd代表最后一个stage

######### stage中只有一个rdd

####### 递归\+遍历

######## 递归

######### 以stage换言之以shuffleDep为边界

######## 遍历

######### 寻找shuffleDep的过程是触发的遍历

####### 回归过程中触发task调度提交

####### stage

######## task的数量是最后一个RDD的分区的数量决定的

######## 最佳计算位置

######## stage会产生一个taskbinary，并广播出去

######## 一个stage根据分区数，产生对应的task

######## 最终将tasks填充到taskset

######### 触发TaskScheduler

###### 3，TaskScheduler

####### schdduleMode

######## FIFO

######## Pair

####### TaskSetManager

###### 4，Executor

####### runtask

######## SparkEnv

######### memoryManager

########## executionMemory

########## memoryStroe

######### blockManager

########## mem

########## disk

######### mapoutputracker

######### nettytransformserver

######### sortShuffleManager

######## task

######### 1，输入

########## hadooprdd

########## persist

########## checkpoint

########## shuffle\-reader

######### 2，计算

########## pipeline：iter

######### 3，输出

########## shuffle\-writer

########## result

######## sortShuffleManager

######### registerHandle

######### getWriter

########## bypass

########## base

########### map

########### buffer

########## unsafe

######### getReader

########## dep

########### iter

######## BlockManager

######### shuffle\-writer

########## 结果

########### disk

######### persist

########## StroageLevel

########### MemoryOnly

########### MemoryAndDisk

########### ser

######### broadcast

######## taskmemoryManager

######### 每task一个

######### 计算过程中

########## shuffle\-writer

########### unsafe

########### base

########### 计算过程中的缓冲区
